PORT=3000

# OpenAI-compatible self-hosted endpoint (Ollama, vLLM, llama.cpp server)
LLM_BASE_URL=http://localhost:11434/v1
LLM_MODEL=llama3.1:8b
# LLM_API_KEY=
